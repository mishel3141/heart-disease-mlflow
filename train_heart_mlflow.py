# –Ü–º–ø–æ—Ä—Ç–∏
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from ucimlrepo import fetch_ucirepo
import time
import mlflow
import mlflow.sklearn
from pyngrok import ngrok

# –î–∞–Ω—ñ: –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ UCI
heart = fetch_ucirepo(id=45)
df = pd.concat([heart.data.features, heart.data.targets], axis=1)

# –¶—ñ–ª—å
df.rename(columns={"num": "target"}, inplace=True)
df["target"] = df["target"].apply(lambda x: 1 if x > 0 else 0)

print("–†–æ–∑–ø–æ–¥—ñ–ª —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó:\n", df["target"].value_counts())

# üßπ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
print("–ü—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:\n", df.isna().sum())

# –í–∏–¥–∞–ª—è—î–º–æ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∞–±–æ –∑–∞–ø–æ–≤–Ω—é—î–º–æ
df.dropna(inplace=True)  # –∞–±–æ df.fillna(...)

# –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó –≤—Ä—É—á–Ω—É
categorical_features = ['cp', 'restecg', 'slope', 'thal', 'sex', 'fbs', 'exang']
for col in categorical_features:
    df[col] = df[col].astype("category")

# –ß–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏
numeric_features = df.drop(columns=["target"] + categorical_features).columns.tolist()

# –û–∑–Ω–∞–∫–∏ —Ç–∞ —Ü—ñ–ª—å
X = df.drop(columns="target")
y = df["target"]

# –†–æ–∑–±–∏—Ç—Ç—è
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å–æ—Ä
numeric_transformer = Pipeline(steps=[("scaler", StandardScaler())])
categorical_transformer = Pipeline(steps=[("onehot", OneHotEncoder(drop="first", handle_unknown="ignore"))])
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features),
    ]
)

# Pipeline
pipeline = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", RandomForestClassifier(random_state=42)),
    ]
)

# –ü–∞—Ä–∞–º–µ—Ç—Ä–∏
params = {
    "classifier__n_estimators": [100, 200],
    "classifier__max_depth": [5, None],
    "classifier__min_samples_split": [2, 5],
}

# –ü–æ—à—É–∫
grid_search = GridSearchCV(pipeline, param_grid=params, cv=5, scoring="accuracy")
grid_search.fit(X_train, y_train)

# –û—Ü—ñ–Ω–∫–∞
y_pred = grid_search.best_estimator_.predict(X_test)
print("\n–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω–∏–π –∑–≤—ñ—Ç:\n", classification_report(y_test, y_pred))
print(f"–õ—ñ–ø—à–∏–π score: {grid_search.best_score_:.4f}")
print(f"–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {grid_search.best_params_}")

# MLflow
mlflow_ui_port = 5000
ngrok.kill()
time.sleep(2)
ngrok_tunnel = ngrok.connect(mlflow_ui_port)

ngrok.set_auth_token("–¢–£–¢_–¢–í–Ü–ô_NGROK_TOKEN")
ngrok_tunnel = ngrok.connect(mlflow_ui_port)
mlflow.set_tracking_uri(ngrok_tunnel.public_url)
print("MLflow UI –¥–æ—Å—Ç—É–ø–Ω–∏–π –∑–∞ –∞–¥—Ä–µ—Å–æ—é:", ngrok_tunnel.public_url)

mlflow.set_experiment("HeartDisease")
with mlflow.start_run():
    mlflow.log_params(grid_search.best_params_)
    mlflow.log_metric("best_score", grid_search.best_score_)
    mlflow.sklearn.log_model(grid_search.best_estimator_, "model")
